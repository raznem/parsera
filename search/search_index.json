{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to Parsera","text":"<p>Parsera is a lightweight Python library for scraping websites with LLMs. </p> <p>There are 2 ways of using Parsera:  </p> <ul> <li>Install the library and run it locally, it is great for smaller-scale extraction and experiments.</li> <li>Use an API that provides a more scalable way of data extraction out of the box. Also, it contains some extra features like a built-in proxy. </li> </ul>"},{"location":"#community","title":"Community","text":"<p>If you like this project star it on GitHub and join our discussions on Discord server.</p>"},{"location":"#contributors","title":"Contributors","text":"<p>If you are considering contributing to Parsera, check out the guidelines to get started.</p>"},{"location":"contributing/","title":"Contributing","text":"<p>Thanks for considering contributing to Parsera!  This project is in the early stage of development, so any help will be highly appreciated. You can start from looking through existing issues, or directly asking about the most helpful contributions on Discord.</p>"},{"location":"contributing/#issues","title":"Issues","text":"<p>The best way to ask a question, report a bug, or submit feature request is to submit an Issue. It's much better than asking about it in email or Discord since conversation becomes publicly available and easy to navigate.</p>"},{"location":"contributing/#pull-requests","title":"Pull requests","text":""},{"location":"contributing/#installation-and-setup","title":"Installation and setup","text":"<p>Fork the repository on GitHub and clone your fork locally.  </p> <p>Next, install dependencies using poetry: <pre><code># Clone your fork and cd into the repo directory\ngit clone git@github.com:&lt;your username&gt;/parsera.git\ncd parsera\n\n# If you don't have poetry install it first:\n# https://python-poetry.org/docs/\n# Then:\npoetry install\n# If you are using VS Code you can get python venv path to switch:\npoetry which python\n# To activate virtual environment with installation run:\npoetry shell\n</code></pre> Now you have a virtual environment with Parsera and all necessary dependencies installed.</p>"},{"location":"contributing/#code-style","title":"Code style","text":"<p>The project uses <code>black</code> and <code>isort</code> for formatting. Set up them in your IDE or run this before committing: <pre><code>make format\n</code></pre></p>"},{"location":"contributing/#commit-and-push-changes","title":"Commit and push changes","text":"<p>Commit your changes and push them to your fork, then create a pull request to the Parsera's repository.</p> <p>Thanks a lot for helping improve Parsera!</p>"},{"location":"getting-started/","title":"Welcome to Parsera","text":"<p>Parsera is a lightweight Python library for scraping websites with LLMs. You can run clone and run it locally or use an API, which provides more scalable way and some extra features like built-in proxy.</p>"},{"location":"getting-started/#installation","title":"Installation","text":"<pre><code>pip install parsera\nplaywright install\n</code></pre>"},{"location":"getting-started/#basic-usage","title":"Basic usage","text":"<p>If you want to use OpenAI, remember to set up <code>OPENAI_API_KEY</code> env variable. You can do this from python with: <pre><code>import os\n\nos.environ[\"OPENAI_API_KEY\"] = \"YOUR_OPENAI_API_KEY_HERE\"\n</code></pre></p> <p>Next, you can run a basic version that uses <code>gpt-4o-mini</code> <pre><code>from parsera import Parsera\n\nurl = \"https://news.ycombinator.com/\"\nelements = {\n    \"Title\": \"News title\",\n    \"Points\": \"Number of points\",\n    \"Comments\": \"Number of comments\",\n}\n\nscraper = Parsera()\nresult = scraper.run(url=url, elements=elements)\n</code></pre></p> <p><code>result</code> variable will contain a json with a list of records: <pre><code>[\n   {\n      \"Title\":\"Hacking the largest airline and hotel rewards platform (2023)\",\n      \"Points\":\"104\",\n      \"Comments\":\"24\"\n   },\n    ...\n]\n</code></pre></p> <p>There is also <code>arun</code> async method available: <pre><code>result = await scrapper.arun(url=url, elements=elements)\n</code></pre></p>"},{"location":"getting-started/#running-with-cli","title":"Running with CLI","text":"<p>Before you run <code>Parsera</code> as command line tool don't forget to put your <code>OPENAI_API_KEY</code> to env variables or <code>.env</code> file</p>"},{"location":"getting-started/#usage","title":"Usage","text":"<p>You can configure elements to parse using <code>JSON string</code> or <code>FILE</code>. Optionally, you can provide <code>FILE</code> to write output.</p> <pre><code>python -m parsera.main URL {--scheme '{\"title\":\"h1\"}' | --file FILENAME} [--output FILENAME]\n</code></pre>"},{"location":"getting-started/#more-features","title":"More features","text":"<p>Check out further documentation to explore more features:</p> <ul> <li>Running custom models</li> <li>Using proxy</li> <li>Run custom playwright</li> <li>Extractors</li> <li>Docker</li> </ul>"},{"location":"api/getting-started/","title":"Getting started","text":"<p>First, go to Parsera web page and generate an API key.</p> <p>Paste this key to <code>X-API-KEY</code> header to send the request: <pre><code>curl https://api.parsera.org/v1/extract \\\n--header 'Content-Type: application/json' \\\n--header 'X-API-KEY: &lt;YOUR_API_KEY&gt;' \\\n--data '{\n    \"url\": \"https://news.ycombinator.com/\",\n    \"attributes\": [\n        {\n            \"name\": \"Title\",\n            \"description\": \"News title\"\n        },\n        {\n            \"name\": \"Points\",\n            \"description\": \"Number of points\"\n        }\n    ],\n    \"proxy_country\": \"UnitedStates\"\n}'\n</code></pre></p> <p>By default, <code>proxy_country</code> is random, it's recommended to set <code>proxy_country</code> parameter to a specific country in the request since a page could not be available from all locations. Here you can find a full list of proxy countries available.</p> <p>You can also explore Swagger doc of the API following this link: https://api.parsera.org/docs#/.</p>"},{"location":"api/proxy/","title":"Proxy","text":""},{"location":"api/proxy/#setting-proxy-country","title":"Setting proxy country","text":"<p>You can use the <code>proxy_country</code> parameter to set a proxy country. The default is <code>random</code>, and it's recommended to change it since your page could not be available from all locations.</p> <p>To scrape the page from the United States you have to set <code>proxy_country</code> to <code>UnitedStates</code>: <pre><code>curl https://api.parsera.org/v1/extract \\\n--header 'Content-Type: application/json' \\\n--header 'X-API-KEY: &lt;YOUR-API-KEY&gt;' \\\n--data '{\n    \"url\": &lt;TARGET-URL&gt;,\n    \"attributes\": [\n        {\n            \"name\": &lt;First attribute name&gt;,\n            \"description\": &lt;First attribute description&gt;,\n        },\n        {\n            \"name\": &lt;Second attribute name&gt;,\n            \"description\": &lt;Second attribute description&gt;\n        }\n    ],\n    \"proxy_country\": \"UnitedStates\"\n}'\n</code></pre></p>"},{"location":"api/proxy/#list-of-proxy-countries","title":"List of proxy countries","text":"<p>Send a <code>GET</code> request to this URL https://api.parsera.org/v1/proxy-countries, to get the list of countries programmatically.</p> <p>Here is the list of countries available:</p> <ul> <li>Random Country - <code>random</code></li> <li>Afghanistan - <code>Afghanistan</code></li> <li>Albania - <code>Albania</code></li> <li>Algeria - <code>Algeria</code></li> <li>Argentina - <code>Argentina</code></li> <li>Armenia - <code>Armenia</code></li> <li>Aruba - <code>Aruba</code></li> <li>Australia - <code>Australia</code></li> <li>Austria - <code>Austria</code></li> <li>Azerbaijan - <code>Azerbaijan</code></li> <li>Bahamas - <code>Bahamas</code></li> <li>Bahrain - <code>Bahrain</code></li> <li>Bangladesh - <code>Bangladesh</code></li> <li>Belarus - <code>Belarus</code></li> <li>Belgium - <code>Belgium</code></li> <li>Bosnia and Herzegovina - <code>BosniaandHerzegovina</code></li> <li>Brazil - <code>Brazil</code></li> <li>British Virgin Islands - <code>BritishVirginIslands</code></li> <li>Brunei - <code>Brunei</code></li> <li>Bulgaria - <code>Bulgaria</code></li> <li>Cambodia - <code>Cambodia</code></li> <li>Cameroon - <code>Cameroon</code></li> <li>Canada - <code>Canada</code></li> <li>Chile - <code>Chile</code></li> <li>China - <code>China</code></li> <li>Colombia - <code>Colombia</code></li> <li>Costa Rica - <code>CostaRica</code></li> <li>Croatia - <code>Croatia</code></li> <li>Cuba - <code>Cuba</code></li> <li>Cyprus - <code>Cyprus</code></li> <li>Chechia - <code>Chechia</code></li> <li>Denmark - <code>Denmark</code></li> <li>Dominican Republic - <code>DominicanRepublic</code></li> <li>Ecuador - <code>Ecuador</code></li> <li>Egypt - <code>Egypt</code></li> <li>El Salvador - <code>ElSalvador</code></li> <li>Estonia - <code>Estonia</code></li> <li>Ethiopia - <code>Ethiopia</code></li> <li>Finland - <code>Finland</code></li> <li>France - <code>France</code></li> <li>Georgia - <code>Georgia</code></li> <li>Germany - <code>Germany</code></li> <li>Ghana - <code>Ghana</code></li> <li>Greece - <code>Greece</code></li> <li>Guatemala - <code>Guatemala</code></li> <li>Guyana - <code>Guyana</code></li> <li>Hashemite Kingdom of Jordan - <code>HashemiteKingdomofJordan</code></li> <li>Hong Kong - <code>HongKong</code></li> <li>Hungary - <code>Hungary</code></li> <li>India - <code>India</code></li> <li>Indonesia - <code>Indonesia</code></li> <li>Iran - <code>Iran</code></li> <li>Iraq - <code>Iraq</code></li> <li>Ireland - <code>Ireland</code></li> <li>Israel - <code>Israel</code></li> <li>Italy - <code>Italy</code></li> <li>Jamaica - <code>Jamaica</code></li> <li>Japan - <code>Japan</code></li> <li>Kazakhstan - <code>Kazakhstan</code></li> <li>Kenya - <code>Kenya</code></li> <li>Kosovo - <code>Kosovo</code></li> <li>Kuwait - <code>Kuwait</code></li> <li>Latvia - <code>Latvia</code></li> <li>Liechtenstein - <code>Liechtenstein</code></li> <li>Luxembourg - <code>Luxembourg</code></li> <li>Macedonia - <code>Macedonia</code></li> <li>Madagascar - <code>Madagascar</code></li> <li>Malaysia - <code>Malaysia</code></li> <li>Mauritius - <code>Mauritius</code></li> <li>Mexico - <code>Mexico</code></li> <li>Mongolia - <code>Mongolia</code></li> <li>Montenegro - <code>Montenegro</code></li> <li>Morocco - <code>Morocco</code></li> <li>Mozambique - <code>Mozambique</code></li> <li>Myanmar - <code>Myanmar</code></li> <li>Nepal - <code>Nepal</code></li> <li>Netherlands - <code>Netherlands</code></li> <li>New Zealand - <code>NewZealand</code></li> <li>Nigeria - <code>Nigeria</code></li> <li>Norway - <code>Norway</code></li> <li>Oman - <code>Oman</code></li> <li>Pakistan - <code>Pakistan</code></li> <li>Palestine - <code>Palestine</code></li> <li>Panama - <code>Panama</code></li> <li>Papua New Guinea - <code>PapuaNewGuinea</code></li> <li>Paraguay - <code>Paraguay</code></li> <li>Peru - <code>Peru</code></li> <li>Philippines - <code>Philippines</code></li> <li>Poland - <code>Poland</code></li> <li>Portugal - <code>Portugal</code></li> <li>Puerto Rico - <code>PuertoRico</code></li> <li>Qatar - <code>Qatar</code></li> <li>Republic of Lithuania - <code>RepublicOfLithuania</code></li> <li>Republic of Moldova - <code>RepublicOfMoldova</code></li> <li>Romania - <code>Romania</code></li> <li>Russia - <code>Russia</code></li> <li>Saudi Arabia - <code>SaudiArabia</code></li> <li>Senegal - <code>Senegal</code></li> <li>Serbia - <code>Serbia</code></li> <li>Seychelles - <code>Seychelles</code></li> <li>Singapore - <code>Singapore</code></li> <li>Slovakia - <code>Slovakia</code></li> <li>Slovenia - <code>Slovenia</code></li> <li>Somalia - <code>Somalia</code></li> <li>South Africa - <code>SouthAfrica</code></li> <li>South Korea - <code>SouthKorea</code></li> <li>Spain - <code>Spain</code></li> <li>Sri Lanka - <code>SriLanka</code></li> <li>Sudan - <code>Sudan</code></li> <li>Suriname - <code>Suriname</code></li> <li>Sweden - <code>Sweden</code></li> <li>Switzerland - <code>Switzerland</code></li> <li>Syria - <code>Syria</code></li> <li>Taiwan - <code>Taiwan</code></li> <li>Tajikistan - <code>Tajikistan</code></li> <li>Thailand - <code>Thailand</code></li> <li>Trinidad and Tobago - <code>TrinidadandTobago</code></li> <li>Tunisia - <code>Tunisia</code></li> <li>Turkey - <code>Turkey</code></li> <li>Uganda - <code>Uganda</code></li> <li>Ukraine - <code>Ukraine</code></li> <li>United Arab Emirates - <code>UnitedArabEmirates</code></li> <li>United Kingdom - <code>UnitedKingdom</code></li> <li>United States - <code>UnitedStates</code></li> <li>Uzbekistan - <code>Uzbekistan</code></li> <li>Venezuela - <code>Venezuela</code></li> <li>Vietnam - <code>Vietnam</code></li> <li>Zambia - <code>Zambia</code></li> </ul>"},{"location":"features/custom-models/","title":"Custom models","text":""},{"location":"features/custom-models/#run-with-custom-model","title":"Run with custom model","text":"<p>You can instantiate <code>Parsera</code> with any chat model supported by LangChain, for example, to run the model from Azure: <pre><code>import os\nfrom langchain_openai import AzureChatOpenAI\n\nllm = AzureChatOpenAI(\n    azure_endpoint=os.getenv(\"AZURE_GPT_BASE_URL\"),\n    openai_api_version=\"2023-05-15\",\n    deployment_name=os.getenv(\"AZURE_GPT_DEPLOYMENT_NAME\"),\n    openai_api_key=os.getenv(\"AZURE_GPT_API_KEY\"),\n    openai_api_type=\"azure\",\n    temperature=0.0,\n)\n\nurl = \"https://news.ycombinator.com/\"\nelements = {\n    \"Title\": \"News title\",\n    \"Points\": \"Number of points\",\n    \"Comments\": \"Number of comments\",\n}\nscrapper = Parsera(model=llm)\nresult = scrapper.run(url=url, elements=elements)\n</code></pre></p>"},{"location":"features/custom-models/#run-local-model-with-trasformers","title":"Run local model with <code>Trasformers</code>","text":"<p>Currently, we only support models that include a <code>system</code> token</p> <p>You should install <code>Transformers</code> with either <code>pytorch</code> (recommended) or <code>TensorFlow 2.0</code></p> <p>Transformers Installation Guide</p> <p>Example: <pre><code>from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\nfrom parsera.engine.model import HuggingFaceModel\nfrom parsera import Parsera\n\n# Define the URL and elements to scrape\nurl = \"https://news.ycombinator.com/\"\nelements = {\n\"Title\": \"News title\",\n\"Points\": \"Number of points\",\n\"Comments\": \"Number of comments\",\n}\n\n# Initialize model with transformers pipeline\ntokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-128k-instruct\", trust_remote_code=True)\nmodel = AutoModelForCausalLM.from_pretrained(\"microsoft/Phi-3-mini-128k-instruct\", trust_remote_code=True)\npipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, max_new_tokens=5000)\n\n# Initialize HuggingFaceModel\nllm = HuggingFaceModel(pipeline=pipe)\n\n# Scrapper with HuggingFace model\nscrapper = Parsera(model=llm)\nresult = scrapper.run(url=url, elements=elements)\n</code></pre></p>"},{"location":"features/custom-playwright/","title":"Custom playwright","text":""},{"location":"features/custom-playwright/#parserascript","title":"ParseraScript","text":"<p>With <code>ParseraScript</code> class you can execute custom playwright scripts during scraping. There are 2 types of code you can run:</p> <ul> <li><code>initial_script</code> which is executed during the first run of <code>ParseraScript</code>, useful when you need to log in to access the data.</li> <li><code>playwright_script</code> which runs during every <code>run</code> call, which allows to do custom actions before data is extracted, useful when data is hidden behind some button.</li> </ul>"},{"location":"features/custom-playwright/#example-log-in-and-load-data","title":"Example: log in and load data","text":"<p>You can log in to parsera.org and get credits amount with the following code: <pre><code>from playwright.async_api import Page\nfrom parsera import ParseraScript\n\n# Define the script to execute during the session creation\nasync def initial_script(page: Page) -&gt; Page:\n    await page.goto(\"https://parsera.org/auth/sign-in\")\n    await page.wait_for_load_state(\"networkidle\")\n    await page.get_by_label(\"Email\").fill(EMAIL)\n    await page.get_by_label(\"Password\").fill(PASSWORD)\n    await page.get_by_role(\"button\", name=\"Sign In\", exact=True).click()\n    await page.wait_for_selector(\"text=Playground\")\n    return page\n\n# This script is executed after the url is opened\nasync def repeating_script(page: Page) -&gt; Page:\n    await page.wait_for_timeout(1000)  # Wait one second for page to load\n    return page\n\nparsera = ParseraScript(model=model, initial_script=initial_script)\nresult = await parsera.arun(\n    url=\"https://parsera.org/app\",\n    elements={\n        \"credits\": \"number of credits\",\n    },\n    playwright_script=repeating_script,\n)\n</code></pre></p>"},{"location":"features/custom-playwright/#access-playwright-instance","title":"Access Playwright instance","text":"<p>The page is fetched via the <code>ParseraScript.loader</code>, which contains the playwright instance. <pre><code>from parsera import ParseraScript\n\nparsera = ParseraScript(model=model)\n\n## You can manually initialize playwright session and modify it:\nawait parsera.new_session()\nawait parsera.loader.load_content(url=url)\n\n## After page is loaded you can access playwright elements, like Page:\nparsera.loader.page.getByRole('button').click()\n\n## Next you cun run extraction process\nresult = await parsera.arun(\n    url=extraction_url,\n    elements=elements_dict,\n)\n</code></pre></p>"},{"location":"features/docker/","title":"Docker","text":""},{"location":"features/docker/#running-in-docker","title":"Running in Docker","text":"<p>You can get access to the CLI or development environment using Docker.</p>"},{"location":"features/docker/#prerequisites","title":"Prerequisites","text":"<ul> <li>Docker: Install Docker</li> <li>Docker Compose: Install Docker Compose</li> </ul>"},{"location":"features/docker/#quickstart","title":"Quickstart","text":"<ol> <li>Create a .env file in the project root directory with the following content:</li> </ol> <pre><code>URL=https://parsera.org\nFILE=/app/scheme.json\nOUTPUT=/app/output/result.json\n</code></pre> <ol> <li> <p>Create <code>scheme.json</code> file with the parsing scheme in the repository root directory.</p> </li> <li> <p>Run <code>make up</code> in this directory.</p> </li> <li> <p>The output will be saved as <code>output/results.json</code> file.</p> </li> </ol>"},{"location":"features/docker/#docker-make-targets","title":"Docker Make Targets","text":"<pre><code>make build # Build Docker image\n\nmake up # Start containers using Docker Compose\n\nmake down # Stop and remove containers using Docker Compose\n\nmake restart # Restart containers using Docker Compose\n\nmake logs # View logs of the containers\n\nmake shell # Open a shell in the running container\n\nmake clean # Remove all stopped containers, unused networks, and dangling images\n</code></pre>"},{"location":"features/extractors/","title":"Extractors","text":""},{"location":"features/extractors/#different-extractor-types","title":"Different extractor types","text":"<p>There are different types of extractors, that provide output in different formats:</p> <ul> <li><code>TabularExtractor</code> for tables.</li> <li><code>ListExtractor</code> for separate lists of values.</li> <li><code>ItemExtractor</code> for specific values.</li> </ul> <p>By default a tabular extractor is used.</p>"},{"location":"features/extractors/#tabular-extractor","title":"Tabular extractor","text":"<p><pre><code>from parsera import Parsera\n\nscraper = Parsera(extractor=Parsera.ExtractorType.TABULAR)\n</code></pre> The tabular extractor is used to find rows of tabular data and has output of the form: <pre><code>[\n    {\"name\": \"name1\", \"price\": \"100\"},\n    {\"name\": \"name2\", \"price\": \"150\"},\n    {\"name\": \"name3\", \"price\": \"300\"},\n]\n</code></pre></p>"},{"location":"features/extractors/#list-extractor","title":"List extractor","text":"<p><pre><code>from parsera import Parsera\n\nscraper = Parsera(extractor=Parsera.ExtractorType.LIST)\n</code></pre> The list extractor is used to find lists of different values and has output of the form: <pre><code>{\n    \"name\": [\"name1\", \"name2\", \"name3\"],\n    \"price\": [\"100\", \"150\", \"300\"]\n}\n</code></pre></p>"},{"location":"features/extractors/#item-extractor","title":"Item extractor","text":"<p><pre><code>from parsera import Parsera\n\nscraper = Parsera(extractor=Parsera.ExtractorType.ITEM)\n</code></pre> The item extractor is used to get singular items from a page like a title or price and has output of the form: <pre><code>{\n    \"name\": \"name1\",\n    \"price\": \"100\"\n}\n</code></pre></p>"},{"location":"features/proxy/","title":"Proxy","text":""},{"location":"features/proxy/#using-proxy","title":"Using proxy","text":"<p>You can use serve the traffic via proxy server when calling <code>run</code> method: <pre><code>proxy_settings = {\n    \"server\": \"https://1.2.3.4:5678\",\n    \"username\": &lt;PROXY_USERNAME&gt;,\n    \"password\": &lt;PROXY_PASSWORD&gt;,\n}\nresult = scrapper.run(url=url, elements=elements, proxy_settings=proxy_settings)\n</code></pre></p> <p>Where <code>proxy_settings</code> contains your proxy credentials.</p>"}]}